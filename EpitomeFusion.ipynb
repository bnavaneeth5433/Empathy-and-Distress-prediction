{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f25dd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "from utils import utils\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from transformers.trainer_utils import set_seed\n",
    "from transformers import RobertaTokenizer\n",
    "from transformers import AutoConfig, AutoModelWithHeads\n",
    "from transformers.adapters.composition import Fuse\n",
    "from transformers import TrainingArguments, EvalPrediction, AdapterTrainer\n",
    "from utils.evaluation import compute_pearsonr\n",
    "\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "set_seed(RANDOM_SEED)\n",
    "\n",
    "dateTimeObj = datetime.now()\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e41ad65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emotional-reactions eval_f1_macro 87.23\n",
    "emo_adapter_path = \"./trained_adapters/emotional-reactions\"\n",
    "\n",
    "# explorations eval_f1_macro 85.92\n",
    "exp_adapter_path = \"./trained_adapters/explorations\"\n",
    "\n",
    "# interpretations eval_f1_macro 57.67\n",
    "int_adapter_path = \"./trained_adapters/interpretations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7909d8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "approach='EpitomeFusion'\n",
    "\n",
    "\"\"\" choose from the options: distress, empathy \"\"\"\n",
    "prediction_task='distress'\n",
    "prediction_task='empathy'\n",
    "\n",
    "\n",
    "\"\"\" set training output directory \"\"\"\n",
    "training_output_dir = f\"./training_output/{approach}_{prediction_task}_{dateTimeObj.hour}{dateTimeObj.minute}-{dateTimeObj.day}-{dateTimeObj.month}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3b4a1a",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8964bfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" load data \"\"\"\n",
    "\n",
    "train_data, val_data, test_data = utils.load_wassa_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ecd8171",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" get task labels \"\"\"\n",
    "\n",
    "train_labels = list(train_data[prediction_task].values)\n",
    "val_labels = list(val_data[prediction_task].values)\n",
    "test_labels = list(test_data[prediction_task].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c6355e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Prepare dataset for training: feature encodings \"\"\"\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "train_encodings = tokenizer(list(train_data['essay'].values), truncation=True, padding=True)\n",
    "val_encodings = tokenizer(list(val_data['essay'].values), truncation=True, padding=True)\n",
    "test_encodings = tokenizer(list(test_data['essay'].values), truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9649922e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" setup torch dataset \"\"\"\n",
    "\n",
    "class WassaDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = WassaDataset(train_encodings, train_labels)\n",
    "val_dataset = WassaDataset(val_encodings, val_labels)\n",
    "test_dataset = WassaDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd8e1fd",
   "metadata": {},
   "source": [
    "# Train Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7ce31f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nbalguri/.local/lib/python3.9/site-packages/transformers/adapters/models/roberta/adapter_model.py:274: FutureWarning: This class has been renamed to `RobertaAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "/home/nbalguri/.local/lib/python3.9/site-packages/transformers/adapters/models/roberta/adapter_model.py:252: FutureWarning: This class has been renamed to `RobertaAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" init model \"\"\"\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    \"roberta-base\",\n",
    "    num_labels=1\n",
    ")\n",
    "model = AutoModelWithHeads.from_pretrained(\n",
    "    \"roberta-base\",\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f49534b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" load epitome empathy adapters \"\"\"\n",
    "\n",
    "er_adapter = model.load_adapter(emo_adapter_path, \n",
    "                                load_as=f'{prediction_task}-emotional-reactions')\n",
    "ex_adapter = model.load_adapter(exp_adapter_path, \n",
    "                                load_as=f'{prediction_task}-explorations')\n",
    "ip_adapter = model.load_adapter(int_adapter_path, \n",
    "                                load_as=f'{prediction_task}-interpretations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9aba326c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" adapter composition \"\"\"\n",
    "\n",
    "# fusion layer\n",
    "model.add_adapter_fusion(Fuse(er_adapter, ex_adapter, ip_adapter))\n",
    "model.set_active_adapters(Fuse(er_adapter, ex_adapter, ip_adapter))\n",
    "\n",
    "# classification head for target task\n",
    "model.add_classification_head(f\"{approach}-{prediction_task}\", num_labels=1)\n",
    "\n",
    "adapter_setup = Fuse(er_adapter, ex_adapter, ip_adapter)\n",
    "model.train_adapter_fusion(adapter_setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9013ea72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "\"\"\" training arguments \"\"\"\n",
    "from transformers import TrainingArguments, EvalPrediction, AdapterTrainer\n",
    "\n",
    "num_train_epochs=10\n",
    "per_device_train_batch_size=8\n",
    "per_device_eval_batch_size=8\n",
    "metric_for_best_model='eval_pearsonr'\n",
    "warmup_steps=1000\n",
    "weight_decay=0.1\n",
    "learning_rate=5e-05\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=training_output_dir,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    per_device_eval_batch_size=per_device_eval_batch_size,\n",
    "    learning_rate=learning_rate,\n",
    "    warmup_steps=warmup_steps,\n",
    "    weight_decay=weight_decay,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=50,\n",
    "    eval_steps=50,\n",
    "    save_steps=50,\n",
    "    evaluation_strategy='steps',\n",
    "    disable_tqdm=False,\n",
    "    overwrite_output_dir=True,\n",
    "    remove_unused_columns=False,\n",
    "    save_strategy='steps',\n",
    "#     load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_for_best_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e041b626",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" init adapter trainer \"\"\"\n",
    "\n",
    "trainer = AdapterTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_pearsonr,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d98254c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nbalguri/.local/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1860\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2330\n",
      "  Number of trainable parameters = 23622154\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2330' max='2330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2330/2330 4:40:48, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearsonr</th>\n",
       "      <th>Pearsonr Scipy</th>\n",
       "      <th>Pval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>19.359300</td>\n",
       "      <td>15.811317</td>\n",
       "      <td>-0.246100</td>\n",
       "      <td>-0.246131</td>\n",
       "      <td>0.000043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>14.497700</td>\n",
       "      <td>10.323250</td>\n",
       "      <td>-0.190600</td>\n",
       "      <td>-0.190591</td>\n",
       "      <td>0.001655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>7.516900</td>\n",
       "      <td>3.776831</td>\n",
       "      <td>-0.022500</td>\n",
       "      <td>-0.022499</td>\n",
       "      <td>0.712855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.780300</td>\n",
       "      <td>3.526766</td>\n",
       "      <td>0.230800</td>\n",
       "      <td>0.230770</td>\n",
       "      <td>0.000130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.501100</td>\n",
       "      <td>3.422412</td>\n",
       "      <td>0.304100</td>\n",
       "      <td>0.304077</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.306100</td>\n",
       "      <td>3.223464</td>\n",
       "      <td>0.407900</td>\n",
       "      <td>0.407943</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>3.050200</td>\n",
       "      <td>3.004418</td>\n",
       "      <td>0.401100</td>\n",
       "      <td>0.401079</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.078800</td>\n",
       "      <td>3.013187</td>\n",
       "      <td>0.412900</td>\n",
       "      <td>0.412864</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.804900</td>\n",
       "      <td>2.884973</td>\n",
       "      <td>0.434000</td>\n",
       "      <td>0.433993</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.749700</td>\n",
       "      <td>2.931206</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.426416</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.977400</td>\n",
       "      <td>2.839924</td>\n",
       "      <td>0.441300</td>\n",
       "      <td>0.441318</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.186900</td>\n",
       "      <td>2.740327</td>\n",
       "      <td>0.465900</td>\n",
       "      <td>0.465943</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.692100</td>\n",
       "      <td>2.788916</td>\n",
       "      <td>0.457900</td>\n",
       "      <td>0.457934</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.823800</td>\n",
       "      <td>3.017079</td>\n",
       "      <td>0.479500</td>\n",
       "      <td>0.479510</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.833300</td>\n",
       "      <td>3.336407</td>\n",
       "      <td>0.480400</td>\n",
       "      <td>0.480359</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.676600</td>\n",
       "      <td>2.650848</td>\n",
       "      <td>0.481400</td>\n",
       "      <td>0.481385</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.751400</td>\n",
       "      <td>3.092277</td>\n",
       "      <td>0.462700</td>\n",
       "      <td>0.462748</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.493800</td>\n",
       "      <td>2.797585</td>\n",
       "      <td>0.473300</td>\n",
       "      <td>0.473259</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.589300</td>\n",
       "      <td>2.770023</td>\n",
       "      <td>0.475300</td>\n",
       "      <td>0.475301</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.849300</td>\n",
       "      <td>3.720008</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.426406</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>2.697700</td>\n",
       "      <td>2.808025</td>\n",
       "      <td>0.461200</td>\n",
       "      <td>0.461155</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>2.659700</td>\n",
       "      <td>2.854313</td>\n",
       "      <td>0.461900</td>\n",
       "      <td>0.461853</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>2.345600</td>\n",
       "      <td>2.863981</td>\n",
       "      <td>0.463900</td>\n",
       "      <td>0.463922</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.347400</td>\n",
       "      <td>2.787163</td>\n",
       "      <td>0.473400</td>\n",
       "      <td>0.473433</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>2.577600</td>\n",
       "      <td>2.674234</td>\n",
       "      <td>0.483700</td>\n",
       "      <td>0.483673</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>2.328300</td>\n",
       "      <td>2.860846</td>\n",
       "      <td>0.491700</td>\n",
       "      <td>0.491674</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>2.546400</td>\n",
       "      <td>2.790775</td>\n",
       "      <td>0.468400</td>\n",
       "      <td>0.468364</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.645100</td>\n",
       "      <td>3.156338</td>\n",
       "      <td>0.488000</td>\n",
       "      <td>0.488000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>2.597500</td>\n",
       "      <td>3.229346</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.474995</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.433500</td>\n",
       "      <td>2.760708</td>\n",
       "      <td>0.478700</td>\n",
       "      <td>0.478681</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>2.030500</td>\n",
       "      <td>2.881442</td>\n",
       "      <td>0.481800</td>\n",
       "      <td>0.481834</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>2.293100</td>\n",
       "      <td>2.719911</td>\n",
       "      <td>0.495200</td>\n",
       "      <td>0.495155</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>2.363100</td>\n",
       "      <td>2.621059</td>\n",
       "      <td>0.497600</td>\n",
       "      <td>0.497582</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>2.349200</td>\n",
       "      <td>2.722933</td>\n",
       "      <td>0.497500</td>\n",
       "      <td>0.497494</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>2.141800</td>\n",
       "      <td>2.762255</td>\n",
       "      <td>0.498700</td>\n",
       "      <td>0.498737</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>2.239900</td>\n",
       "      <td>2.803352</td>\n",
       "      <td>0.513800</td>\n",
       "      <td>0.513818</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>2.268900</td>\n",
       "      <td>2.667244</td>\n",
       "      <td>0.513000</td>\n",
       "      <td>0.513026</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>2.100500</td>\n",
       "      <td>3.049711</td>\n",
       "      <td>0.512300</td>\n",
       "      <td>0.512316</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>2.145000</td>\n",
       "      <td>2.653403</td>\n",
       "      <td>0.508900</td>\n",
       "      <td>0.508889</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.190800</td>\n",
       "      <td>3.320874</td>\n",
       "      <td>0.506800</td>\n",
       "      <td>0.506791</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>2.173600</td>\n",
       "      <td>2.675375</td>\n",
       "      <td>0.497000</td>\n",
       "      <td>0.496954</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>2.223800</td>\n",
       "      <td>2.664155</td>\n",
       "      <td>0.499700</td>\n",
       "      <td>0.499736</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>1.789600</td>\n",
       "      <td>2.670308</td>\n",
       "      <td>0.503600</td>\n",
       "      <td>0.503564</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>1.850400</td>\n",
       "      <td>2.688095</td>\n",
       "      <td>0.503900</td>\n",
       "      <td>0.503904</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>2.023200</td>\n",
       "      <td>2.703766</td>\n",
       "      <td>0.501900</td>\n",
       "      <td>0.501949</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>2.133700</td>\n",
       "      <td>2.701064</td>\n",
       "      <td>0.503600</td>\n",
       "      <td>0.503617</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-50\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-50/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-50/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-50/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-50/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-50/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-50/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-50/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-50/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-50/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-50/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-50/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-50/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-50/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-50/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-50/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-50/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-50/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-50/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-50/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-50/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-50/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-50/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-100\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-100/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-100/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-100/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-100/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-100/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-100/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-100/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-100/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-100/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-100/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-100/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-100/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-100/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-100/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-100/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-100/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-100/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-100/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-100/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-100/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-100/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-100/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-150\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-150/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-150/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-150/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-150/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-150/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-150/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-150/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-150/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-150/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-150/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-150/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-150/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-150/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-150/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-150/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-150/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-150/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-150/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-150/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-150/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-150/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-150/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-200\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-200/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-200/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-200/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-200/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-200/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-200/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-200/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-200/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-200/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-200/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-200/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-200/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-200/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-200/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-200/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-200/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-200/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-200/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-200/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-200/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-200/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-200/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-250\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-250/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-250/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-250/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-250/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-250/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-250/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-250/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-250/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-250/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-250/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-250/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-250/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-250/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-250/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-250/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-250/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-250/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-250/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-250/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-250/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-250/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-250/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-300\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-300/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-300/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-300/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-300/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-300/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-300/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-300/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-300/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-300/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-300/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-300/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-300/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-300/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-300/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-300/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-300/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-300/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-300/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-300/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-300/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-300/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-300/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-350\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-350/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-350/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-350/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-350/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-350/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-350/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-350/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-350/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-350/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-350/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-350/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-350/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-350/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-350/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-350/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-350/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-350/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-350/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-350/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-350/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-350/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-350/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-400\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-400/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-400/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-400/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-400/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-400/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-400/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-400/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-400/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-400/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-400/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-400/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-400/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-400/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-400/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-400/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-400/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-400/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-400/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-400/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-400/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-400/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-400/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-450\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-450/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-450/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-450/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-450/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-450/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-450/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-450/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-450/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-450/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-450/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-450/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-450/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-450/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-450/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-450/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-450/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-450/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-450/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-450/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-450/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-450/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-450/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-500\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-500/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-500/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-500/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-500/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-500/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-500/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-500/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-500/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-500/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-500/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-500/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-500/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-500/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-500/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-500/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-500/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-500/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-500/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-500/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-500/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-500/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-500/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-550\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-550/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-550/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-550/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-550/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-550/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-550/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-550/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-550/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-550/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-550/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-550/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-550/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-550/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-550/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-550/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-550/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-550/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-550/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-550/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-550/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-550/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-550/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-600\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-600/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-600/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-600/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-600/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-600/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-600/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-600/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-600/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-600/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-600/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-600/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-600/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-600/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-600/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-600/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-600/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-600/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-600/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-600/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-600/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-600/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-600/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-650\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-650/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-650/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-650/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-650/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-650/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-650/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-650/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-650/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-650/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-650/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-650/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-650/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-650/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-650/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-650/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-650/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-650/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-650/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-650/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-650/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-650/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-650/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-700\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-700/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-700/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-700/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-700/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-700/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-700/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-700/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-700/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-700/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-700/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-700/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-700/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-700/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-700/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-700/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-700/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-700/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-700/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-700/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-700/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-700/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-700/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-750\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-750/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-750/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-750/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-750/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-750/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-750/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-750/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-750/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-750/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-750/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-750/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-750/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-750/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-750/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-750/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-750/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-750/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-750/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-750/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-750/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-750/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-750/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-800\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-800/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-800/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-800/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-800/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-800/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-800/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-800/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-800/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-800/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-800/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-800/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-800/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-800/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-800/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-800/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-800/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-800/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-800/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-800/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-800/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-800/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-800/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-850\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-850/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-850/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-850/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-850/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-850/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-850/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-850/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-850/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-850/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-850/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-850/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-850/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-850/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-850/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-850/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-850/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-850/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-850/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-850/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-850/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-850/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-850/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-900\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-900/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-900/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-900/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-900/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-900/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-900/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-900/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-900/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-900/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-900/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-900/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-900/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-900/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-900/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-900/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-900/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-900/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-900/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-900/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-900/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-900/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-900/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-950\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-950/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-950/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-950/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-950/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-950/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-950/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-950/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-950/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-950/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-950/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-950/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-950/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-950/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-950/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-950/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-950/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-950/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-950/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-950/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-950/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-950/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-950/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1000\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1000/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1000/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1000/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1000/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1000/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1000/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1000/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1000/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1000/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1000/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1000/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1000/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1000/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1000/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1000/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1000/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1000/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1000/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1000/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1000/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1000/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1000/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1050\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1050/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1050/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1050/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1050/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1050/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1050/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1050/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1050/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1050/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1050/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1050/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1050/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1050/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1050/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1050/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1050/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1050/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1050/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1050/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1050/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1050/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1050/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1100\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1100/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1100/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1100/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1100/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1100/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1100/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1100/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1100/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1100/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1100/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1100/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1100/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1100/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1100/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1100/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1100/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1100/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1100/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1100/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1100/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1100/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1100/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1150\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1150/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1150/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1150/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1150/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1150/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1150/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1150/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1150/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1150/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1150/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1150/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1150/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1150/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1150/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1150/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1150/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1150/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1150/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1150/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1150/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1150/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1150/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1200\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1200/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1200/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1200/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1200/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1200/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1200/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1200/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1200/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1200/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1200/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1200/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1200/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1200/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1200/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1200/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1200/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1200/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1200/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1200/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1200/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1200/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1200/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1250\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1250/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1250/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1250/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1250/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1250/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1250/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1250/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1250/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1250/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1250/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1250/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1250/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1250/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1250/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1250/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1250/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1250/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1250/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1250/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1250/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1250/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1250/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1300\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1300/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1300/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1300/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1300/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1300/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1300/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1300/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1300/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1300/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1300/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1300/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1300/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1300/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1300/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1300/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1300/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1300/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1300/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1300/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1300/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1300/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1300/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1350\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1350/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1350/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1350/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1350/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1350/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1350/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1350/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1350/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1350/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1350/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1350/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1350/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1350/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1350/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1350/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1350/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1350/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1350/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1350/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1350/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1350/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1350/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1400\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1400/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1400/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1400/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1400/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1400/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1400/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1400/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1400/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1400/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1400/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1400/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1400/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1400/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1400/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1400/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1400/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1400/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1400/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1400/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1400/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1400/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1400/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1450\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1450/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1450/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1450/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1450/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1450/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1450/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1450/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1450/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1450/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1450/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1450/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1450/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1450/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1450/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1450/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1450/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1450/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1450/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1450/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1450/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1450/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1450/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1500\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1500/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1500/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1500/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1500/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1500/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1500/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1500/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1500/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1500/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1500/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1500/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1500/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1500/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1500/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1500/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1500/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1500/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1500/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1500/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1500/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1500/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1500/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1550\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1550/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1550/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1550/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1550/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1550/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1550/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1550/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1550/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1550/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1550/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1550/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1550/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1550/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1550/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1550/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1550/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1550/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1550/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1550/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1550/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1550/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1550/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1600\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1600/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1600/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1600/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1600/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1600/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1600/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1600/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1600/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1600/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1600/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1600/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1600/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1600/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1600/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1600/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1600/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1600/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1600/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1600/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1600/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1600/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1600/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1650\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1650/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1650/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1650/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1650/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1650/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1650/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1650/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1650/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1650/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1650/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1650/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1650/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1650/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1650/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1650/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1650/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1650/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1650/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1650/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1650/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1650/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1650/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1700\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1700/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1700/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1700/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1700/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1700/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1700/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1700/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1700/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1700/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1700/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1700/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1700/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1700/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1700/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1700/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1700/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1700/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1700/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1700/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1700/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1700/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1700/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1750\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1750/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1750/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1750/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1750/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1750/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1750/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1750/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1750/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1750/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1750/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1750/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1750/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1750/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1750/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1750/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1750/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1750/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1750/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1750/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1750/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1750/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1750/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1850\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1850/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1850/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1850/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1850/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1850/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1850/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1850/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1850/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1850/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1850/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1850/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1850/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1850/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1850/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1850/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1850/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1850/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1850/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1850/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1850/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1850/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1850/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1900\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1900/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1900/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1900/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1900/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1900/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1900/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1900/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1900/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1900/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1900/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1900/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1900/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1900/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1900/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1900/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1900/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1900/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1900/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1900/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1900/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1900/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1900/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1950\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1950/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1950/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1950/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1950/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1950/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1950/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1950/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1950/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1950/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1950/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1950/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1950/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1950/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1950/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1950/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1950/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1950/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1950/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1950/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1950/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1950/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1950/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2000\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2000/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2000/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2000/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2000/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2000/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2000/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2000/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2000/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2000/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2000/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2000/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2000/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2000/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2000/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2000/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2000/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2000/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2000/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2000/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2000/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2000/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2000/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2050\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2050/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2050/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2050/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2050/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2050/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2050/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2050/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2050/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2050/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2050/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2050/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2050/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2050/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2050/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2050/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2050/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2050/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2050/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2050/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2050/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2050/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2050/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2100\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2100/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2100/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2100/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2100/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2100/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2100/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2100/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2100/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2100/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2100/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2100/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2100/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2100/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2100/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2100/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2100/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2100/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2100/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2100/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2100/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2100/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2100/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2150\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2150/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2150/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2150/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2150/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2150/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2150/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2150/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2150/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2150/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2150/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2150/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2150/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2150/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2150/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2150/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2150/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2150/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2150/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2150/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2150/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2150/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2150/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2200\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2200/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2200/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2200/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2200/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2200/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2200/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2200/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2200/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2200/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2200/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2200/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2200/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2200/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2200/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2200/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2200/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2200/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2200/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2200/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2200/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2200/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2200/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2250\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2250/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2250/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2250/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2250/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2250/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2250/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2250/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2250/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2250/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2250/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2250/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2250/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2250/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2250/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2250/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2250/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2250/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2250/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2250/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2250/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2250/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2250/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2300\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2300/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2300/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2300/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2300/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2300/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2300/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2300/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2300/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2300/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2300/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2300/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2300/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2300/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2300/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2300/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2300/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2300/empathy-explorations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2300/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2300/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2300/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2300/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-2300/EpitomeFusion-empathy/pytorch_model_head.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2330, training_loss=3.2676859794256514, metrics={'train_runtime': 16854.9211, 'train_samples_per_second': 1.104, 'train_steps_per_second': 0.138, 'total_flos': 2761147486188000.0, 'train_loss': 3.2676859794256514, 'epoch': 10.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca27e56",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fec29083",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading module configuration from ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800/empathy-emotional-reactions/adapter_config.json\n",
      "Overwriting existing adapter 'empathy-emotional-reactions'.\n",
      "Loading module weights from ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Loading module configuration from ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800/empathy-emotional-reactions/head_config.json\n",
      "Overwriting existing head 'empathy-emotional-reactions'\n",
      "Adding head 'empathy-emotional-reactions' with config {'head_type': 'classification', 'num_labels': 3, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'0': 0, '1': 1, '2': 2}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Loading module configuration from ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800/empathy-explorations/adapter_config.json\n",
      "Overwriting existing adapter 'empathy-explorations'.\n",
      "Loading module weights from ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800/empathy-explorations/pytorch_adapter.bin\n",
      "Loading module configuration from ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800/empathy-explorations/head_config.json\n",
      "Overwriting existing head 'empathy-explorations'\n",
      "Adding head 'empathy-explorations' with config {'head_type': 'classification', 'num_labels': 3, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'0': 0, '1': 1, '2': 2}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800/empathy-explorations/pytorch_model_head.bin\n",
      "Loading module configuration from ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800/empathy-interpretations/adapter_config.json\n",
      "Overwriting existing adapter 'empathy-interpretations'.\n",
      "Loading module weights from ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800/empathy-interpretations/pytorch_adapter.bin\n",
      "Loading module configuration from ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800/empathy-interpretations/head_config.json\n",
      "Overwriting existing head 'empathy-interpretations'\n",
      "Adding head 'empathy-interpretations' with config {'head_type': 'classification', 'num_labels': 3, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'0': 0, '1': 1, '2': 2}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800/empathy-interpretations/pytorch_model_head.bin\n",
      "Loading module configuration from ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/adapter_fusion_config.json\n",
      "Overwriting existing adapter fusion module 'empathy-emotional-reactions,empathy-explorations,empathy-interpretations'\n",
      "Loading module weights from ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800/empathy-emotional-reactions,empathy-explorations,empathy-interpretations/pytorch_model_adapter_fusion.bin\n",
      "No matching prediction head found in './training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800/empathy-emotional-reactions,empathy-explorations,empathy-interpretations'\n",
      "Could not identify valid prediction head(s) from setup 'Fuse[empathy-emotional-reactions, empathy-explorations, empathy-interpretations]'.\n",
      "Loading module configuration from ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800/EpitomeFusion-empathy/head_config.json\n",
      "Overwriting existing head 'EpitomeFusion-empathy'\n",
      "Adding head 'EpitomeFusion-empathy' with config {'head_type': 'classification', 'num_labels': 1, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from ./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800/EpitomeFusion-empathy/pytorch_model_head.bin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./training_output/EpitomeFusion_empathy_1014-7-4/checkpoint-1800/EpitomeFusion-empathy',\n",
       " 'EpitomeFusion-empathy')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" load best model \"\"\"\n",
    "\n",
    "# load each individual adapter\n",
    "model.load_adapter(\n",
    "    trainer.state.best_model_checkpoint + f'/{er_adapter}'\n",
    ")\n",
    "model.load_adapter(\n",
    "    trainer.state.best_model_checkpoint + f'/{ex_adapter}'\n",
    ")\n",
    "model.load_adapter(\n",
    "    trainer.state.best_model_checkpoint + f'/{ip_adapter}'\n",
    ")\n",
    "\n",
    "# load adapter fusion\n",
    "model.load_adapter_fusion(\n",
    "    trainer.state.best_model_checkpoint + f\"/{er_adapter},{ex_adapter},{ip_adapter}\"\n",
    ")\n",
    "\n",
    "# set active adapters\n",
    "model.set_active_adapters(Fuse(er_adapter, ex_adapter, ip_adapter))\n",
    "\n",
    "# load head\n",
    "model.load_head(trainer.state.best_model_checkpoint + f'/{approach}-{prediction_task}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1069de13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 270\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 01:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eval_loss</td>\n",
       "      <td>2.803352e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eval_pearsonr</td>\n",
       "      <td>5.138000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eval_pearsonr_scipy</td>\n",
       "      <td>5.138177e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eval_pval</td>\n",
       "      <td>1.359033e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eval_runtime</td>\n",
       "      <td>7.189480e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>eval_samples_per_second</td>\n",
       "      <td>3.755000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>eval_steps_per_second</td>\n",
       "      <td>4.730000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>epoch</td>\n",
       "      <td>1.000000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    metric         value\n",
       "0                eval_loss  2.803352e+00\n",
       "1            eval_pearsonr  5.138000e-01\n",
       "2      eval_pearsonr_scipy  5.138177e-01\n",
       "3                eval_pval  1.359033e-19\n",
       "4             eval_runtime  7.189480e+01\n",
       "5  eval_samples_per_second  3.755000e+00\n",
       "6    eval_steps_per_second  4.730000e-01\n",
       "7                    epoch  1.000000e+01"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" output eval metrics from best model \"\"\"\n",
    "\n",
    "#trainer.model.cuda()\n",
    "eval_output = trainer.evaluate()\n",
    "eval_result = eval_output[metric_for_best_model]\n",
    "\n",
    "pd.DataFrame({'metric':list(eval_output.keys()), 'value': list(eval_output.values())}, columns=['metric', 'value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffcc67b",
   "metadata": {},
   "source": [
    "# Test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebf5fdc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 525\n",
      "  Batch size = 8\n",
      "/app/home/alahnala/miniconda3/envs/st/lib/python3.9/site-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "\"\"\" make predictions on test dataset \"\"\"\n",
    "\n",
    "p = trainer.predict(test_dataset)\n",
    "preds = p.predictions[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19899d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved predictions to ./predictions/empathy/EpitomeFusion-eval_pearsonr-50.78_1838-21-4.tsv\n"
     ]
    }
   ],
   "source": [
    "\"\"\" save predictions \"\"\"\n",
    "\n",
    "pred_file = f\"{approach}-{metric_for_best_model}-{round(eval_result * 100, 4)}_{dateTimeObj.hour}{dateTimeObj.minute}-{dateTimeObj.day}-{dateTimeObj.month}.tsv\"\n",
    "pred_path = f'./predictions/{prediction_task}/{pred_file}'\n",
    "os.makedirs(f'./predictions/{prediction_task}/', exist_ok=True)\n",
    "pd.Series(preds).to_csv(pred_path, sep='\\t', header=False, index=False)\n",
    "print(\"saved predictions to\",pred_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31003fd5",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23608d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./trained_adapters/EpitomeFusion-empathy/empathy-emotional-reactions/adapter_config.json\n",
      "Module weights saved in ./trained_adapters/EpitomeFusion-empathy/empathy-emotional-reactions/pytorch_adapter.bin\n",
      "Configuration saved in ./trained_adapters/EpitomeFusion-empathy/empathy-emotional-reactions/head_config.json\n",
      "Module weights saved in ./trained_adapters/EpitomeFusion-empathy/empathy-emotional-reactions/pytorch_model_head.bin\n",
      "Configuration saved in ./trained_adapters/EpitomeFusion-empathy/empathy-explorations/adapter_config.json\n",
      "Module weights saved in ./trained_adapters/EpitomeFusion-empathy/empathy-explorations/pytorch_adapter.bin\n",
      "Configuration saved in ./trained_adapters/EpitomeFusion-empathy/empathy-explorations/head_config.json\n",
      "Module weights saved in ./trained_adapters/EpitomeFusion-empathy/empathy-explorations/pytorch_model_head.bin\n",
      "Configuration saved in ./trained_adapters/EpitomeFusion-empathy/empathy-interpretations/adapter_config.json\n",
      "Module weights saved in ./trained_adapters/EpitomeFusion-empathy/empathy-interpretations/pytorch_adapter.bin\n",
      "Configuration saved in ./trained_adapters/EpitomeFusion-empathy/empathy-interpretations/head_config.json\n",
      "Module weights saved in ./trained_adapters/EpitomeFusion-empathy/empathy-interpretations/pytorch_model_head.bin\n",
      "Configuration saved in ./trained_adapters/EpitomeFusion-empathy/adapter_fusion_config.json\n",
      "Module weights saved in ./trained_adapters/EpitomeFusion-empathy/pytorch_model_adapter_fusion.bin\n",
      "Configuration saved in ./trained_adapters/EpitomeFusion-empathy/head_config.json\n",
      "Module weights saved in ./trained_adapters/EpitomeFusion-empathy/pytorch_model_head.bin\n"
     ]
    }
   ],
   "source": [
    "\"\"\" set path for where to save the adapter \"\"\"\n",
    "adapter_save_path = f\"./trained_adapters/{approach}-{prediction_task}\"\n",
    "\n",
    "\"\"\" save each individual adapter \"\"\"\n",
    "os.makedirs(adapter_save_path + f\"/{er_adapter}\", exist_ok=True)\n",
    "trainer.model.save_adapter(adapter_save_path + f\"/{er_adapter}\", er_adapter)\n",
    "\n",
    "os.makedirs(adapter_save_path + f\"/{ex_adapter}\", exist_ok=True)\n",
    "trainer.model.save_adapter(adapter_save_path + f\"/{ex_adapter}\", ex_adapter)\n",
    "\n",
    "os.makedirs(adapter_save_path + f\"/{ip_adapter}\", exist_ok=True)\n",
    "trainer.model.save_adapter(adapter_save_path + f\"/{ip_adapter}\", ip_adapter)\n",
    "\n",
    "\"\"\" save fusion \"\"\"\n",
    "model.save_adapter_fusion(adapter_save_path, f\"{er_adapter},{ex_adapter},{ip_adapter}\")\n",
    "\n",
    "\"\"\" save head \"\"\"\n",
    "model.save_head(adapter_save_path, f\"{approach}-{prediction_task}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
