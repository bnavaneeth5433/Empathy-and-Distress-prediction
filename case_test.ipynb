{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8tcEvcFMBjw3",
        "outputId": "5920c4cc-0b96-4f8a-da01-90e296e0d54d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting adapter-transformers\n",
            "  Downloading adapter_transformers-3.2.1-py3-none-any.whl (6.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0 (from adapter-transformers)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from adapter-transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->adapter-transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->adapter-transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->adapter-transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->adapter-transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->adapter-transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->adapter-transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, adapter-transformers\n",
            "Successfully installed adapter-transformers-3.2.1 huggingface-hub-0.14.1 tokenizers-0.13.3\n"
          ]
        }
      ],
      "source": [
        "!pip install -U adapter-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYqHfnKZBsI9"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision torchaudio -f https://download.pytorch.org/whl/cu111/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xdsvj4tmBuKb"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoConfig, AutoModelWithHeads\n",
        "import torch\n",
        "from transformers import RobertaTokenizer\n",
        "import transformers.adapters.composition as ac\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from scipy.stats import pearsonr\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3WZXOfWBwXB"
      },
      "outputs": [],
      "source": [
        "val_data = pd.read_csv('/content/drive/MyDrive/NLP_final_pro/data/messages_dev_features_ready_for_WS_2022.tsv', sep='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWzUd83hBz4G"
      },
      "outputs": [],
      "source": [
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "\n",
        "config = AutoConfig.from_pretrained(\n",
        "    \"roberta-base\",\n",
        "    num_labels=1\n",
        ")\n",
        "\n",
        "model = AutoModelWithHeads.from_pretrained(\n",
        "    \"roberta-base\",\n",
        "    config=config,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvSB79BoB3wD"
      },
      "outputs": [],
      "source": [
        "\"\"\" load adapters \"\"\"\n",
        "empathy_adapter_path = \"/content/drive/MyDrive/NLP_final_pro/trained_adapters/EMP_emotion_stack\"\n",
        "distress_adapter_path = \"/content/drive/MyDrive/NLP_final_pro/trained_adapters/DIS_emotion_stack\"\n",
        "\n",
        "empathy_adapter = model.load_adapter(empathy_adapter_path, load_as=empathy_adapter_path.split('/')[-1])\n",
        "distress_adapter = model.load_adapter(distress_adapter_path, load_as=distress_adapter_path.split('/')[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oncyEjU8B6zh"
      },
      "outputs": [],
      "source": [
        "model.set_active_adapters(ac.Parallel(empathy_adapter, distress_adapter))\n",
        "model.active_head = ['EMP_emotion_stack', 'DIS_emotion_stack']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exL72V0_B7bo"
      },
      "outputs": [],
      "source": [
        "\"\"\" load pretrained adapter composition \"\"\"\n",
        "\n",
        "from transformers.adapters.composition import Fuse\n",
        "\n",
        "\n",
        "fusion_path = f\"/content/drive/MyDrive/NLP_final_pro/trained_adapters/EpitomeFusion-distress\"\n",
        "\n",
        "# load each individual adapter\n",
        "dis_er_adapter = model.load_adapter(\n",
        "                fusion_path + '/distress-emotional-reactions')\n",
        "dis_ex_adapter = model.load_adapter(\n",
        "                fusion_path + '/distress-explorations')\n",
        "dis_ip_adapter = model.load_adapter(\n",
        "                fusion_path + '/distress-interpretations')\n",
        "\n",
        "# load adapter fusion\n",
        "model.load_adapter_fusion(\n",
        "    fusion_path\n",
        ")\n",
        "\n",
        "# set active adapters\n",
        "model.set_active_adapters(Fuse(dis_er_adapter, dis_ex_adapter, dis_ip_adapter))\n",
        "\n",
        "# # load head\n",
        "# path, distress_adapter = model.load_head(fusion_path)\n",
        "\n",
        "model.active_head = 'EpitomeFusion-distress'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPK6oB7uB9tF"
      },
      "outputs": [],
      "source": [
        "\"\"\" load pretrained adapter composition: empathy \"\"\"\n",
        "\n",
        "fusion_path = f\"/content/drive/MyDrive/NLP_final_pro/trained_adapters/EpitomeFusion-empathy\"\n",
        "\n",
        "# load each individual adapter\n",
        "emp_er_adapter = model.load_adapter(\n",
        "                fusion_path + '/empathy-emotional-reactions'\n",
        "            )\n",
        "emp_ex_adapter = model.load_adapter(\n",
        "                fusion_path + '/empathy-explorations'\n",
        "            )\n",
        "emp_ip_adapter = model.load_adapter(\n",
        "                fusion_path + '/empathy-interpretations'\n",
        "            )\n",
        "\n",
        "# load adapter fusion\n",
        "model.load_adapter_fusion(\n",
        "    fusion_path\n",
        ")\n",
        "\n",
        "# set active adapters\n",
        "model.set_active_adapters(Fuse(emp_er_adapter, emp_ex_adapter, emp_ip_adapter))\n",
        "\n",
        "# # load head\n",
        "# path, empathy_adapter = model.load_head(fusion_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTETW5bdB_w-"
      },
      "outputs": [],
      "source": [
        "model.active_head = 'EpitomeFusion-empathy'\n",
        "model.active_head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ObjAl3rCB93"
      },
      "outputs": [],
      "source": [
        "def predict_sen(sentence):\n",
        "    tokens = tokenizer.tokenize(sentence)\n",
        "    input_ids = torch.tensor(tokenizer.convert_tokens_to_ids(tokens)).to('cuda')\n",
        "\n",
        "    # move the model to the GPU\n",
        "    model.to('cuda')\n",
        "\n",
        "    # set active adapters\n",
        "    model.set_active_adapters(Fuse(dis_er_adapter, dis_ex_adapter, dis_ip_adapter))\n",
        "    model.active_head = 'EpitomeFusion-distress'\n",
        "    outputs = model(input_ids)\n",
        "    dis_score_f = outputs.logits[0][0].tolist()\n",
        "\n",
        "    # set active adapters\n",
        "    model.set_active_adapters(Fuse(emp_er_adapter, emp_ex_adapter, emp_ip_adapter))\n",
        "    model.active_head = 'EpitomeFusion-empathy'\n",
        "    outputs = model(input_ids)\n",
        "    emp_score_f = outputs.logits[0][0].tolist()\n",
        "\n",
        "    # stack\n",
        "    model.set_active_adapters(ac.Parallel(empathy_adapter, distress_adapter))\n",
        "    model.active_head = ['EMP_emotion_stack', 'DIS_emotion_stack']\n",
        "    outputs = model(input_ids)\n",
        "\n",
        "    emp_score_s = outputs[0].logits[0][0].tolist()\n",
        "    dis_score_s = outputs[1].logits[0][0].tolist()\n",
        "\n",
        "    # move the model back to the CPU\n",
        "    model.to('cpu')\n",
        "\n",
        "    return emp_score_f, dis_score_f, emp_score_s, dis_score_s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1qYBw3ACHNS"
      },
      "outputs": [],
      "source": [
        "sen = val_data['essay'].tolist()\n",
        "random_five = random.sample(sen, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1shY92fD0kB"
      },
      "outputs": [],
      "source": [
        "for se in random_five:\n",
        "  emp_score_f, dis_score_f, emp_score_s, dis_score_s = predict_sen(se)\n",
        "  print(se)\n",
        "  print(\"emp_score_f =\",emp_score_f, \"dis_score_f =\",dis_score_f,\"emp_score_s =\", emp_score_s,\"dis_score_s =\" ,dis_score_s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISrLRcSLEhKX"
      },
      "outputs": [],
      "source": [
        "re_sen = [\"\",\n",
        "          \"\",\n",
        "          \"\",\n",
        "          \"\",\n",
        "          \"\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgQtzskrErhb"
      },
      "outputs": [],
      "source": [
        "for re_sen in random_five:\n",
        "  emp_score_f, dis_score_f, emp_score_s, dis_score_s = predict_sen(se)\n",
        "  print(se)\n",
        "  print(\"emp_score_f =\",emp_score_f, \"dis_score_f =\",dis_score_f,\"emp_score_s =\", emp_score_s,\"dis_score_s =\" ,dis_score_s)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}